{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddf8d4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\super\\DAG\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from scipy.linalg import lu, solve_triangular, det, inv\n",
    "from numpy.linalg import LinAlgError, inv\n",
    "import SCM_data\n",
    "import MEC\n",
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "# Soft-thresholding operator for matrices\n",
    "def soft_threshold_matrix(A, threshold):\n",
    "    return np.sign(A) * np.maximum(np.abs(A) - threshold, 0.0)\n",
    "\n",
    "# Compute the gradient of f(A) = -2 log det A + trace(A^T R_hat A)\n",
    "def compute_gradient(A, R_hat):\n",
    "    epsilon = 1e-6\n",
    "    try:\n",
    "        A_inv = inv(A)\n",
    "    except LinAlgError:\n",
    "        print(\"Warning: singular matrix encountered. Adding epsilon * I.\")\n",
    "        A_inv = inv(A + epsilon * np.eye(A.shape[0]))\n",
    "    return 2 * R_hat @ A - 2 * A_inv\n",
    "\n",
    "# Objective function value\n",
    "def objective(A, R_hat, lam):\n",
    "    sign, logdet = np.linalg.slogdet(A)\n",
    "    if sign <= 0:\n",
    "        return np.inf\n",
    "    trace_term = np.trace(A.T @ R_hat @ A)\n",
    "    return -2 * logdet + trace_term + lam * np.sum(np.abs(A))\n",
    "\n",
    "# Proximal gradient algorithm for matrix A\n",
    "def nodag(R_hat, lam = 0.1, alpha=0.5, max_iter=100, tol=1e-5,init = None, verbose=False):\n",
    "    p = R_hat.shape[0]\n",
    "    if init is None:\n",
    "        A = np.eye(p)  # Initialization\n",
    "    else:\n",
    "        A = init\n",
    "    step = 1.0\n",
    "\n",
    "    for k in range(max_iter):\n",
    "        A_old = A.copy()\n",
    "        grad = compute_gradient(A, R_hat)\n",
    "\n",
    "        # Line search loop\n",
    "        for _ in range(100):\n",
    "            A_temp = soft_threshold_matrix(A - step * grad, step * lam)\n",
    "            try:\n",
    "                f_temp = objective(A_temp, R_hat, lam)\n",
    "                f_curr = objective(A, R_hat, lam)\n",
    "                g_temp = lam * np.sum(np.abs(A_temp))\n",
    "                g_curr = lam * np.sum(np.abs(A))\n",
    "\n",
    "                # Beck & Teboulle condition\n",
    "                diff = A_temp - A\n",
    "                v = np.sum((grad * diff)) + (np.linalg.norm(diff, 'fro') ** 2) / (2 * step)\n",
    "                if f_temp <= f_curr + v and f_temp + g_temp <= f_curr + g_curr:\n",
    "                    break\n",
    "                else:\n",
    "                    step *= alpha  # reduce step\n",
    "            except np.linalg.LinAlgError:\n",
    "                step *= alpha  # if det or inv fails, shrink step\n",
    "\n",
    "        A = A_temp\n",
    "        if verbose:\n",
    "            if k % 1000 == 0:\n",
    "                likelihood = -2 * np.log(np.linalg.det(A)) + np.trace(A.T @ R_hat @ A)\n",
    "                print(f\"Iteration {k}: likelihood = {likelihood}\")\n",
    "\n",
    "        # Convergence check\n",
    "        if np.linalg.norm(A - A_old, ord='fro') < tol:\n",
    "            if verbose == True:\n",
    "                print(f\"Iteration {k}: break\")\n",
    "            break\n",
    "        \n",
    "    likelihood = -2 * np.log(np.linalg.det(A)) + np.trace(A.T @ R_hat @ A)\n",
    "    sparsity = lam * np.sum(np.abs(A))\n",
    "\n",
    "    return A, likelihood, sparsity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dec94703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_to_adjacency(W, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Convert a weight matrix to an adjacency matrix.\n",
    "    \n",
    "    Parameters:\n",
    "        W (np.ndarray): Weight matrix (square matrix).\n",
    "        threshold (float): Values with absolute weight <= threshold are treated as 0.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Binary adjacency matrix of the same shape.\n",
    "    \"\"\"\n",
    "    if not isinstance(W, np.ndarray):\n",
    "        raise TypeError(\"Input W must be a numpy array.\")\n",
    "    if W.shape[0] != W.shape[1]:\n",
    "        raise ValueError(\"Input W must be a square matrix.\")\n",
    "    \n",
    "    G = (np.abs(W) > threshold).astype(int)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86b637e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta_true\n",
      " [[ 2. -1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1. -1.  2.]]\n",
      "Sigma_true\n",
      " [[1. 1. 0.]\n",
      " [1. 3. 1.]\n",
      " [0. 1. 1.]]\n",
      "Warning: singular matrix encountered. Adding epsilon * I.\n",
      "Iteration 0: likelihood = 20126660195616.137\n",
      "Iteration 259: break\n",
      "False\n",
      "G_true = \n",
      " [[0 1 0]\n",
      " [0 0 0]\n",
      " [0 1 0]]\n",
      "G_est = \n",
      " [[1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]]\n",
      "A_est = \n",
      " [[ 1.22656673 -0.32772511  0.22399825]\n",
      " [-0.33520821  0.75186236 -0.33644307]\n",
      " [ 0.22424808 -0.32918123  1.21872634]]\n",
      "likelihood_true_2 =  3.0\n",
      "likelihood_est =  3.0392714692596976\n",
      "sparsity_est =  0.49739593917754243\n",
      "diff =  0.0392714692596976\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "# test\n",
    "n = 10000\n",
    "W_true = np.array([[0, 1, 0], [0, 0, 0], [0, 1, 0]])\n",
    "Omega_true = np.eye(3)\n",
    "Theta_true = (np.eye(3) - W_true) @ inv(Omega_true) @ (np.eye(3) - W_true.T)\n",
    "print(\"Theta_true\\n\", Theta_true)\n",
    "Sigma_true = inv(Theta_true)\n",
    "print(\"Sigma_true\\n\",Sigma_true)\n",
    "\n",
    "X, Y, Z, G_true, CPDAG = SCM_data.generate_scm_data(3, n_samples=n)\n",
    "\n",
    "data = np.array([X, Y, Z]).T\n",
    "\n",
    "#likelihood_true = np.linalg.slogdet(Theta_true)[1]-np.trace(data @ Theta_true @ data.T)/n\n",
    "\n",
    "A_true = (np.eye(3) - W_true) @ inv(sqrtm(Omega_true))\n",
    "likelihood_true_2 = - 2 * np.log(np.linalg.det(A_true)) + np.trace(A_true.T @ Sigma_true @ A_true)\n",
    "\n",
    "init = np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
    "\n",
    "R_hat = np.cov(np.array([X, Y, Z]))\n",
    "A_est, likelihood_est, sparsity_est = nodag(R_hat, max_iter=10000,init = init, verbose=True)\n",
    "W_est = np.eye(3) - A_est\n",
    "G_est = weight_to_adjacency(W_est, 0.1)\n",
    "print(MEC.is_in_markov_equiv_class(G_true, G_est))\n",
    "print(\"G_true = \\n\",G_true)\n",
    "print(\"G_est = \\n\",G_est)\n",
    "print(\"A_est = \\n\",A_est)\n",
    "# print(\"likelihood_true = \",likelihood_true)\n",
    "print(\"likelihood_true_2 = \",likelihood_true_2)\n",
    "print(\"likelihood_est = \",likelihood_est)\n",
    "print(\"sparsity_est = \",sparsity_est)\n",
    "print(\"diff = \", likelihood_est - likelihood_true_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cac749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(Theta, X):\n",
    "    n = X.shape[0]\n",
    "    return np.linalg.slogdet(Theta)[1] - np.trace(X @ Theta @ X.T) / n\n",
    "\n",
    "def train_multiple_nodag_trials(R_hat, X, Theta_true, n_trials=10, verbose = False):\n",
    "    d = R_hat.shape[0]\n",
    "    best_result = None\n",
    "    best_diff = float('inf')\n",
    "    results = []\n",
    "\n",
    "   \n",
    "    ll_true = log_likelihood(Theta_true, X)\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        A_init = np.random.normal(scale=1, size=(d, d))\n",
    "        np.fill_diagonal(A_init, 1.0)  \n",
    "\n",
    "        A_est, likelihood_est, sparsity_est = nodag(R_hat, max_iter = 10000, init = A_init)\n",
    "\n",
    "        diff = abs(likelihood_est - ll_true)\n",
    "        results.append((i, diff, likelihood_est, A_init, A_est))    \n",
    "\n",
    "        if verbose == True:\n",
    "            print(f\"[Trial {i}] LogLik = {likelihood_est:.4f}, Diff = {diff:.6f}\")\n",
    "\n",
    "        if diff < best_diff:\n",
    "            best_result = (i, diff, likelihood_est, A_init, A_est)\n",
    "            best_diff = diff\n",
    "\n",
    "    best_i, best_diff, best_ll, best_init, best_A = best_result\n",
    "    print(\"\\n✅ Best Trial:\")\n",
    "    print(f\"  Trial Index      = {best_i}\")\n",
    "    print(f\"  Log-Likelihood   = {best_ll:.4f}\")\n",
    "    print(f\"  LL Diff to Truth = {best_diff:.6f}\")\n",
    "    print(f\" Best init matrix:\\n\", best_init)\n",
    "\n",
    "    return best_A, best_ll, best_diff, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03051afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta_true\n",
      " [[ 2. -1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1. -1.  2.]]\n",
      "Sigma_true\n",
      " [[1. 1. 0.]\n",
      " [1. 3. 1.]\n",
      " [0. 1. 1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood_true =  -3.008174905798895\n",
      "\n",
      "✅ Best Trial:\n",
      "  Trial Index      = 6\n",
      "  Log-Likelihood   = 3.0731\n",
      "  LL Diff to Truth = 6.081314\n",
      " Best init matrix:\n",
      " [[ 1.          0.17640832  0.56648302]\n",
      " [ 0.5118715   1.         -0.36525408]\n",
      " [ 0.56588891 -0.57684138  1.        ]]\n",
      "G_true = \n",
      " [[0 1 0]\n",
      " [0 0 0]\n",
      " [0 1 0]]\n",
      "G_est = \n",
      " [[1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]]\n",
      "A_est = \n",
      " [[ 1.12094228 -0.3003065   0.233333  ]\n",
      " [-0.28321754  0.74835811 -0.33778562]\n",
      " [ 0.1743131  -0.33798551  1.22281997]]\n"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "W_true = np.array([[0, 1, 0], [0, 0, 0], [0, 1, 0]])\n",
    "Omega_true = np.eye(3)\n",
    "Theta_true = (np.eye(3) - W_true) @ inv(Omega_true) @ (np.eye(3) - W_true.T)\n",
    "print(\"Theta_true\\n\", Theta_true)\n",
    "Sigma_true = inv(Theta_true)\n",
    "print(\"Sigma_true\\n\",Sigma_true)\n",
    "\n",
    "X, Y, Z, G_true, CPDAG = SCM_data.generate_scm_data(3, n_samples=n)\n",
    "\n",
    "data = np.array([X, Y, Z]).T\n",
    "likelihood_true = np.linalg.slogdet(Theta_true)[1]-np.trace(data @ Theta_true @ data.T)/n\n",
    "print(\"likelihood_true = \",likelihood_true)\n",
    "A_true = (np.eye(3) - W_true) @ inv(sqrtm(Omega_true))\n",
    "R_hat = np.cov(np.array([X, Y, Z]))\n",
    "A_est, best_likelihood, best_diff, results = train_multiple_nodag_trials(R_hat, data, Theta_true, 100)\n",
    "W_est = np.eye(3) - A_est\n",
    "G_est = weight_to_adjacency(W_est, 0.1)\n",
    "print(\"G_true = \\n\",G_true)\n",
    "print(\"G_est = \\n\",G_est)\n",
    "print(\"A_est = \\n\",A_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56db3a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0.]\n",
      " [1. 3. 1.]\n",
      " [0. 1. 1.]]\n",
      "3.0000957007924645\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [ 1.23109931, -0.50780174,  0.45404282],\n",
    "    [-0.28575097,  0.83222012, -0.46476196],\n",
    "    [ 0.14120805, -0.38342536,  1.34691221]\n",
    "])\n",
    "print(Sigma_true)\n",
    "print( - 2 * np.log(np.linalg.det(A)) + np.trace(A.T @ Sigma_true @ A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb74259a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe1c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
