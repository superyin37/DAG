{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075df0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, LBFGS\n",
    "from nodag_calm import nocalm\n",
    "from SCM_data import generate_scm_data\n",
    "import numpy as np\n",
    "from numpy.linalg import LinAlgError, inv\n",
    "from scipy.linalg import sqrtm\n",
    "import MEC\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd816de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta_true\n",
      " [[ 2. -1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1. -1.  2.]]\n",
      "Sigma_true\n",
      " [[1. 1. 0.]\n",
      " [1. 3. 1.]\n",
      " [0. 1. 1.]]\n",
      "A_true = \n",
      " [[ 1. -1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0. -1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# True Graph\n",
    "n = 10000\n",
    "W_true = np.array([[0, 1, 0], [0, 0, 0], [0, 1, 0]])\n",
    "Omega_true = np.eye(3)\n",
    "Theta_true = (np.eye(3) - W_true) @ inv(Omega_true) @ (np.eye(3) - W_true.T)\n",
    "print(\"Theta_true\\n\", Theta_true)\n",
    "Sigma_true = inv(Theta_true)\n",
    "print(\"Sigma_true\\n\",Sigma_true)\n",
    "\n",
    "\n",
    "# Data\n",
    "X, Y, Z, G_true, CPDAG = generate_scm_data(3, n_samples=n)\n",
    "\n",
    "data = np.array([X, Y, Z]).T\n",
    "R_hat = np.cov(data.T)\n",
    "A_true = (np.eye(3) - W_true) @ inv(sqrtm(Omega_true))\n",
    "likelihood_true = - 2 * np.log(np.linalg.det(A_true)) + np.trace(A_true.T @ Sigma_true @ A_true)\n",
    "print(\"A_true = \\n\",A_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "068d94b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01539005  0.00091678 -0.01718084]\n",
      " [ 0.00087682 -0.01081938 -0.00922021]\n",
      " [-0.00075618  0.00362606 -0.00717282]]\n",
      "[[-1.  0.  0.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0. -1.]]\n"
     ]
    }
   ],
   "source": [
    "A_est, B_est, info = nocalm(\n",
    "        R_hat, lam=1, beta=10.0, delta=1e-6,\n",
    "        max_steps=2000, optimizer_type=\"lbfgs\", lr=0.1, history_every=1000,\n",
    "        dtype=torch.float64\n",
    "    )\n",
    "\n",
    "print(A_est)\n",
    "print(B_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "468cb458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0320391   0.00154878 -0.01517699]\n",
      " [ 0.01353939 -0.00429054 -0.03923077]\n",
      " [-0.01726469 -0.0379868  -0.0515936 ]]\n",
      "[[-1.  0.  0.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "A_init = np.array([[1, 1, 0],[0, 1, 0],[0, 1, 1]])\n",
    "A_est, B_est, info = nocalm(\n",
    "        R_hat, lam=1, beta=10.0, delta=1e-6,\n",
    "        max_steps=2000, optimizer_type=\"adam\", lr=0.1, history_every=1000,\n",
    "        dtype=torch.float64,A_init = A_init\n",
    "    )\n",
    "print(A_est)\n",
    "print(B_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f223d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_est = \n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Final Loss =  2.9558088509832383\n",
      "SCM 1 : 1.0\n",
      "G_est = \n",
      " [[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Final Loss =  4.1827224493009325\n",
      "SCM 2 : 1.0\n",
      "G_est = \n",
      " [[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "Final Loss =  4.542162705376069\n",
      "SCM 3 : 1.0\n",
      "G_est = \n",
      " [[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "Final Loss =  4.640448577672834\n",
      "SCM 4 : 0.0\n",
      "G_est = \n",
      " [[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "Final Loss =  5.094627360415677\n",
      "SCM 5 : 0.0\n"
     ]
    }
   ],
   "source": [
    "# init: ground truth\n",
    "\n",
    "times = 1\n",
    "for i in range(1, 6):\n",
    "    true_count = [0] * 6\n",
    "    for seed in range(times):\n",
    "        X, Y, Z, G_true, CPDAG = generate_scm_data(i,10000, seed = seed)\n",
    "        A_true = (np.eye(3) - G_true)\n",
    "        data = np.array([X, Y, Z]).T\n",
    "        R_hat = np.cov(data.T)\n",
    "        #print(data.T@ data / 10000)\n",
    "        A_est, B_est, info = nocalm(\n",
    "            R_hat, lam=0.5, beta=10.0, \n",
    "            max_steps=2000, optimizer_type=\"lbfgs\", lr=0.1, history_every=1000,\n",
    "            dtype=torch.float64,A_init = A_true + np.eye(G_true.shape[0])\n",
    "    )\n",
    "        \n",
    "        print(\"G_est = \\n\",B_est)\n",
    "        if MEC.is_in_markov_equiv_class(G_true, B_est): true_count[i-1] += 1\n",
    "        print(\"Final Loss = \", info[\"final_loss\"])\n",
    "    print(f\"SCM {i} : {true_count[i-1]/times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f00ccadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss =  26.728871246213973\n",
      "SCM 1 : 1.0\n",
      "Final Loss =  26.735782114956372\n",
      "SCM 2 : 0.0\n",
      "Final Loss =  26.73768297106476\n",
      "SCM 3 : 0.0\n",
      "Final Loss =  26.734634151916467\n",
      "SCM 4 : 0.0\n",
      "Final Loss =  26.758507556006272\n",
      "SCM 5 : 0.0\n"
     ]
    }
   ],
   "source": [
    "# init: 0 matrix\n",
    "\n",
    "times = 1\n",
    "for i in range(1, 6):\n",
    "    true_count = [0] * 6\n",
    "    for seed in range(times):\n",
    "        X, Y, Z, G_true, CPDAG = generate_scm_data(i,10000, seed = seed)\n",
    "        data = np.array([X, Y, Z]).T\n",
    "        R_hat = np.cov(data.T)\n",
    "        #print(data.T@ data / 10000)\n",
    "        A_est, B_est, info = nocalm(\n",
    "            R_hat, lam=1, beta=10.0, delta=1e-6,\n",
    "            max_steps=2000, optimizer_type=\"lbfgs\", lr=0.1, history_every=1000,\n",
    "            dtype=torch.float64)\n",
    "    \n",
    "        \n",
    "        #print(Omega_est)\n",
    "        #print(inv(np.eye(3)-W_est.T)@ Omega_est @ inv(np.eye(3)-W_est))\n",
    "        #print(\"G_true = \\n\",G_true)\n",
    "        #print(\"G_est = \\n\",B_est)\n",
    "        if MEC.is_in_markov_equiv_class(G_true, B_est): true_count[i-1] += 1\n",
    "        print(\"Final Loss = \", info[\"final_loss\"])\n",
    "    print(f\"SCM {i} : {true_count[i-1]/times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e2720f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_est = \n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Final Loss =  2.956224279594004\n",
      "SCM 1 : 1.0\n",
      "G_est = \n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Final Loss =  3.935837845564218\n",
      "SCM 2 : 0.0\n",
      "G_est = \n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Final Loss =  4.919871918173216\n",
      "SCM 3 : 0.0\n",
      "G_est = \n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Final Loss =  5.880016898753651\n",
      "SCM 4 : 0.0\n",
      "G_est = \n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "Final Loss =  6.907718710390206\n",
      "SCM 5 : 0.0\n"
     ]
    }
   ],
   "source": [
    "# init: identity matrix\n",
    "\n",
    "times = 1\n",
    "for i in range(1, 6):\n",
    "    true_count = [0] * 6\n",
    "    for seed in range(times):\n",
    "        X, Y, Z, G_true, CPDAG = generate_scm_data(i,10000, seed = seed)\n",
    "        data = np.array([X, Y, Z]).T\n",
    "        R_hat = np.cov(data.T)\n",
    "        #print(data.T@ data / 10000)\n",
    "        A_est, B_est, info = nocalm(\n",
    "            R_hat, lam=1, beta=10.0, delta=1e-6,\n",
    "            max_steps=2000, optimizer_type=\"lbfgs\", lr=0.1, history_every=1000,\n",
    "            dtype=torch.float64, A_init = np.eye(3))\n",
    "    \n",
    "        \n",
    "        #print(Omega_est)\n",
    "        #print(inv(np.eye(3)-W_est.T)@ Omega_est @ inv(np.eye(3)-W_est))\n",
    "        #print(\"G_true = \\n\",G_true)\n",
    "        print(\"G_est = \\n\",B_est)\n",
    "        if MEC.is_in_markov_equiv_class(G_true, B_est): true_count[i-1] += 1\n",
    "        print(\"Final Loss = \", info[\"final_loss\"])\n",
    "    print(f\"SCM {i} : {true_count[i-1]/times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b7a0c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_est = \n",
      " [[0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 0.]]\n",
      "Final Loss =  7.6075391700848565\n",
      "SCM 1 : 0.0\n",
      "G_est = \n",
      " [[-1.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "Final Loss =  8.924527783315032\n",
      "SCM 2 : 0.0\n",
      "G_est = \n",
      " [[0. 1. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 1. 0.]]\n",
      "Final Loss =  8.869287775387047\n",
      "SCM 3 : 0.0\n",
      "G_est = \n",
      " [[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 1. 0.]]\n",
      "Final Loss =  8.993236222953119\n",
      "SCM 4 : 0.0\n",
      "G_est = \n",
      " [[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "Final Loss =  11.163653030905031\n",
      "SCM 5 : 0.0\n"
     ]
    }
   ],
   "source": [
    "# init: random\n",
    "A_init = np.random.rand(3,3)\n",
    "\n",
    "times = 1\n",
    "for i in range(1, 6):\n",
    "    true_count = [0] * 6\n",
    "    for seed in range(times):\n",
    "        X, Y, Z, G_true, CPDAG = generate_scm_data(i,10000, seed = seed)\n",
    "        data = np.array([X, Y, Z]).T\n",
    "        R_hat = np.cov(data.T)\n",
    "        #print(data.T@ data / 10000)\n",
    "        A_est, B_est, info = nocalm(\n",
    "            R_hat, lam=0.2, beta=10.0, delta=1e-6,\n",
    "            max_steps=5000, optimizer_type=\"lbfgs\", lr=0.1, history_every=1000,\n",
    "            dtype=torch.float64,A_init = A_init)\n",
    "        \n",
    "        #print(Omega_est)\n",
    "        #print(inv(np.eye(3)-W_est.T)@ Omega_est @ inv(np.eye(3)-W_est))\n",
    "        #print(\"G_true = \\n\",G_true)\n",
    "        print(\"G_est = \\n\",B_est)\n",
    "        if MEC.is_in_markov_equiv_class(G_true, B_est): true_count[i-1] += 1\n",
    "        print(\"Final Loss = \", info[\"final_loss\"])\n",
    "    print(f\"SCM {i} : {true_count[i-1]/times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a71089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood_true =  2.9921669186153315\n",
      "penalty_true =  1.9999999917553855\n",
      "f_true =  4.992166910370717\n",
      "A_true = \n",
      " [[ 1. -1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0. -1.  1.]]\n",
      "A_est = \n",
      " [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "G_est = \n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "likelihood_final =  5.0430173873628155\n",
      "penalty_final =  0.0\n",
      "f_final =  5.0430173873628155\n",
      "final loss: 5.0430173873628155\n",
      "final llikelihood: 5.0430173873628155\n",
      "final penalty: 0.0\n"
     ]
    }
   ],
   "source": [
    "# X -> Y <- Z\n",
    "\n",
    "i = 3\n",
    "X, Y, Z, G_true, CPDAG = generate_scm_data(i,10000, seed = 1)\n",
    "data = np.array([X, Y, Z]).T\n",
    "R_hat = np.cov(data.T)\n",
    "Omega_true = np.eye(3)\n",
    "beta = 10\n",
    "lam = 1\n",
    "\n",
    "A_true = (np.eye(3) - G_true) @ inv(sqrtm(Omega_true))\n",
    "likelihood_true = - 2 * np.log(np.linalg.det(A_true)) + np.trace(A_true.T @ R_hat @ A_true)\n",
    "print(\"likelihood_true = \", likelihood_true)\n",
    "\n",
    "\n",
    "true_penalty = lam * np.sum(np.tanh(beta * np.abs(A_true))[~np.eye(A_true.shape[0], dtype=bool)])\n",
    "\n",
    "f_true = likelihood_true + true_penalty\n",
    "print(\"penalty_true = \", true_penalty)\n",
    "print(\"f_true = \", f_true)\n",
    "\n",
    "#print(data.T@ data / 10000)\n",
    "A_est, B_est, info = nocalm(\n",
    "    R_hat, lam=lam, beta=beta, \n",
    "    max_steps=2000, optimizer_type=\"lbfgs\", lr=0.1, history_every=1000,\n",
    "    dtype=torch.float64, A_init = np.eye(3))\n",
    "\n",
    "\n",
    "#print(Omega_est)\n",
    "#print(inv(np.eye(3)-W_est.T)@ Omega_est @ inv(np.eye(3)-W_est))\n",
    "#print(\"G_true = \\n\",G_true)\n",
    "print(\"A_true = \\n\",A_true)\n",
    "print(\"A_est = \\n\", A_est)\n",
    "print(\"G_est = \\n\", B_est)\n",
    "likelihood_final = - 2 * np.log(np.linalg.det(A_est)) + np.trace(A_est.T @ R_hat @ A_est)\n",
    "penalty_final = lam * np.sum(np.tanh(beta * np.abs(A_est))[~np.eye(A_est.shape[0], dtype=bool)])\n",
    "print(\"likelihood_final = \",likelihood_final)\n",
    "print(\"penalty_final = \",penalty_final)\n",
    "print(\"f_final = \", likelihood_final + penalty_final)\n",
    "print(\"final loss:\", info[\"final_loss\"])\n",
    "print(\"final llikelihood:\", info[\"final_llikelihood\"])\n",
    "print(\"final penalty:\", info[\"final_penalty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8d684e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam = 0.01, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 0.01, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 0.021544346900318832, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 0.021544346900318832, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 0.046415888336127774, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 0.046415888336127774, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 0.1, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 0.1, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 0.21544346900318834, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 0.21544346900318834, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 0.46415888336127775, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 0.46415888336127775, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 1.0, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 1.0, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 2.154434690031882, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 2.154434690031882, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 4.6415888336127775, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 4.6415888336127775, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 10.0, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "lam = 10.0, beta = 10\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X, Y, Z, G_true, CPDAG = generate_scm_data(i,10000, seed = 1)\n",
    "data = np.array([X, Y, Z]).T\n",
    "R_hat = np.cov(data.T)\n",
    "Omega_true = np.eye(3)\n",
    "A_true = (np.eye(3) - G_true) @ inv(sqrtm(Omega_true))\n",
    "likelihood_true = - 2 * np.log(np.linalg.det(A_true)) + np.trace(A_true.T @ R_hat @ A_true)\n",
    "\n",
    "lams = np.logspace(np.log10(0.01), np.log10(10), num=10)\n",
    "betas = np.logspace(np.log10(1), np.log10(100), num=10)\n",
    "\n",
    "for lam in (lams):\n",
    "    for beta in (10, 10):\n",
    "        A_est, B_est, info = nocalm(\n",
    "        R_hat,\n",
    "        lam=lam,\n",
    "        beta=beta,\n",
    "        max_steps=2000,\n",
    "        optimizer_type=\"lbfgs\",\n",
    "        lr=0.03,\n",
    "        history_every=500,\n",
    "        dtype=torch.float64,\n",
    "        A_init = A_true\n",
    "    )\n",
    "        if MEC.is_in_markov_equiv_class(G_true, B_est): print(f\"lam = {lam}, beta = {beta}\")\n",
    "        print(B_est)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe858093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in d:\\coding\\anaconda\\lib\\site-packages (from optuna) (1.13.3)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in d:\\coding\\anaconda\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\coding\\anaconda\\lib\\site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in d:\\coding\\anaconda\\lib\\site-packages (from optuna) (2.0.34)\n",
      "Requirement already satisfied: tqdm in d:\\coding\\anaconda\\lib\\site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in d:\\coding\\anaconda\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in d:\\coding\\anaconda\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in d:\\coding\\anaconda\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\coding\\anaconda\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.1)\n",
      "Requirement already satisfied: colorama in d:\\coding\\anaconda\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in d:\\coding\\anaconda\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: colorlog, optuna\n",
      "\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   -------------------- ------------------- 1/2 [optuna]\n",
      "   ---------------------------------------- 2/2 [optuna]\n",
      "\n",
      "Successfully installed colorlog-6.9.0 optuna-4.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb24dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 17:49:09,731] A new study created in memory with name: no-name-bab97863-32b6-4abc-8365-1b2a24aa5530\n",
      "[I 2025-09-07 17:49:11,796] Trial 0 finished with value: 3.008435239296924 and parameters: {'lam': 0.003212672273401207, 'beta': 37.974715219027566}. Best is trial 0 with value: 3.008435239296924.\n",
      "[I 2025-09-07 17:49:13,626] Trial 1 finished with value: 3.079211344880811 and parameters: {'lam': 0.04593955822038763, 'beta': 1.757920248531243}. Best is trial 0 with value: 3.008435239296924.\n",
      "[I 2025-09-07 17:49:15,444] Trial 2 finished with value: 3.0254851440265407 and parameters: {'lam': 0.008290954626115205, 'beta': 30.8690988869943}. Best is trial 0 with value: 3.008435239296924.\n",
      "[I 2025-09-07 17:49:17,167] Trial 3 finished with value: 3.018719703718669 and parameters: {'lam': 0.005610110752202096, 'beta': 38.09855734858557}. Best is trial 0 with value: 3.008435239296924.\n",
      "[I 2025-09-07 17:49:18,983] Trial 4 finished with value: 3.1262959239139643 and parameters: {'lam': 0.06717989695992826, 'beta': 42.46503196472347}. Best is trial 0 with value: 3.008435239296924.\n",
      "[I 2025-09-07 17:49:20,876] Trial 5 finished with value: 3.0126816857454757 and parameters: {'lam': 0.0047397612407450935, 'beta': 24.032804676100362}. Best is trial 0 with value: 3.008435239296924.\n",
      "[I 2025-09-07 17:49:22,813] Trial 6 finished with value: 3.0670500015104376 and parameters: {'lam': 0.037569388252906004, 'beta': 48.93782540126235}. Best is trial 0 with value: 3.008435239296924.\n",
      "[I 2025-09-07 17:49:24,704] Trial 7 finished with value: 4.360557062905391 and parameters: {'lam': 0.7134371087299978, 'beta': 41.74224545958316}. Best is trial 0 with value: 3.008435239296924.\n",
      "[I 2025-09-07 17:49:26,595] Trial 8 finished with value: 3.0055654127673774 and parameters: {'lam': 0.0025286666892412775, 'beta': 48.43907308828102}. Best is trial 8 with value: 3.0055654127673774.\n",
      "[I 2025-09-07 17:49:28,371] Trial 9 finished with value: 2.99634380034834 and parameters: {'lam': 0.001402353701044549, 'beta': 6.227631649647384}. Best is trial 9 with value: 2.99634380034834.\n",
      "[I 2025-09-07 17:49:30,170] Trial 10 finished with value: 2.993800792604806 and parameters: {'lam': 0.0010933092269752632, 'beta': 1.0292700573889908}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:31,946] Trial 11 finished with value: 2.994518646966674 and parameters: {'lam': 0.0012050188686184384, 'beta': 1.6697334875485539}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:33,838] Trial 12 finished with value: 2.996163290822693 and parameters: {'lam': 0.0010754819998691357, 'beta': 11.354688138604766}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:35,640] Trial 13 finished with value: 3.0185069344848583 and parameters: {'lam': 0.01250807862270207, 'beta': 15.830847449103965}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:37,538] Trial 14 finished with value: 3.3188825663889827 and parameters: {'lam': 0.16347336240138924, 'beta': 17.367028340302088}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:39,390] Trial 15 finished with value: 3.021302674304879 and parameters: {'lam': 0.014917346987169474, 'beta': 1.4882680643075394}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:41,319] Trial 16 finished with value: 2.9958252128507814 and parameters: {'lam': 0.0010770251121612411, 'beta': 9.037754553292514}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:43,070] Trial 17 finished with value: 3.001444923426223 and parameters: {'lam': 0.001999230135390219, 'beta': 21.948244861725048}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:44,805] Trial 18 finished with value: 3.2713869721641533 and parameters: {'lam': 0.13973771535893367, 'beta': 13.237567200925849}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:46,626] Trial 19 finished with value: 3.0394930109335268 and parameters: {'lam': 0.02278715578166042, 'beta': 6.08965036276572}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:48,453] Trial 20 finished with value: 3.0033146152477554 and parameters: {'lam': 0.0025229241087094166, 'beta': 19.45665702964121}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:50,246] Trial 21 finished with value: 2.9957728256546168 and parameters: {'lam': 0.0011292160044520138, 'beta': 7.664530645729798}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:52,055] Trial 22 finished with value: 3.005462226445173 and parameters: {'lam': 0.005081704613768844, 'beta': 5.684386970082862}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:53,837] Trial 23 finished with value: 2.9956963447009524 and parameters: {'lam': 0.0016578582122828132, 'beta': 1.9295726388145837}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:55,618] Trial 24 finished with value: 2.9953366981474856 and parameters: {'lam': 0.0018707048969126233, 'beta': 1.120205979397329}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:57,427] Trial 25 finished with value: 3.009960411224296 and parameters: {'lam': 0.0036928109634154233, 'beta': 31.06995792425746}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:49:59,306] Trial 26 finished with value: 3.0146870661694445 and parameters: {'lam': 0.01003288483189861, 'beta': 12.159343266882352}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:01,142] Trial 27 finished with value: 2.9971039579847925 and parameters: {'lam': 0.0017662644093813826, 'beta': 5.0589354899434005}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:02,968] Trial 28 finished with value: 3.8885933938363753 and parameters: {'lam': 0.8599521925191932, 'beta': 10.396076580466666}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:04,756] Trial 29 finished with value: 3.0073350619604233 and parameters: {'lam': 0.003141895340066865, 'beta': 29.023398221308508}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:06,668] Trial 30 finished with value: 3.002631575536927 and parameters: {'lam': 0.005968193953205211, 'beta': 1.0895120901143505}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:08,475] Trial 31 finished with value: 2.996831406282802 and parameters: {'lam': 0.0017987170269819425, 'beta': 3.8272909203643546}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:10,295] Trial 32 finished with value: 2.9964012985883817 and parameters: {'lam': 0.0017114715809325568, 'beta': 3.2119161508840146}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:12,130] Trial 33 finished with value: 3.001992077652909 and parameters: {'lam': 0.0032177656567067225, 'beta': 8.522071117431945}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:13,940] Trial 34 finished with value: 2.9947536099307857 and parameters: {'lam': 0.0010756114321067445, 'beta': 3.2535780435815163}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:15,750] Trial 35 finished with value: 2.9966401263897655 and parameters: {'lam': 0.001083400634575202, 'beta': 15.007593969933607}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:17,638] Trial 36 finished with value: 2.9963830667003832 and parameters: {'lam': 0.002499562852409143, 'beta': 1.0660593558671412}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:19,570] Trial 37 finished with value: 3.010147332660188 and parameters: {'lam': 0.007276131856071357, 'beta': 8.308000344257003}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:21,362] Trial 38 finished with value: 3.0022298584695837 and parameters: {'lam': 0.003765773526452166, 'beta': 4.984774053077915}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:23,129] Trial 39 finished with value: 3.1021928876940303 and parameters: {'lam': 0.054669995588341846, 'beta': 3.811384092450298}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:24,907] Trial 40 finished with value: 3.7554011781515353 and parameters: {'lam': 0.35016279344746587, 'beta': 7.359196899238858}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:26,715] Trial 41 finished with value: 2.995976523684406 and parameters: {'lam': 0.0015573646579540175, 'beta': 3.1285423110134034}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:28,566] Trial 42 finished with value: 2.9946508445347364 and parameters: {'lam': 0.001442938062238597, 'beta': 1.215297620720332}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:30,413] Trial 43 finished with value: 3.000073165563076 and parameters: {'lam': 0.002298144606529582, 'beta': 10.306457756613831}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:32,267] Trial 44 finished with value: 2.9948492995157214 and parameters: {'lam': 0.0010024491415609954, 'beta': 4.701003101612911}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:34,131] Trial 45 finished with value: 2.998933382956815 and parameters: {'lam': 0.0013307624242267606, 'beta': 33.69671249944195}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:35,921] Trial 46 finished with value: 2.9947880541618783 and parameters: {'lam': 0.0010111109406039603, 'beta': 4.247497267099486}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:37,736] Trial 47 finished with value: 3.005521026920627 and parameters: {'lam': 0.004027739889316676, 'beta': 14.04656842140363}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:39,525] Trial 48 finished with value: 2.997019957570143 and parameters: {'lam': 0.001376907141984746, 'beta': 9.9210139377504}. Best is trial 10 with value: 2.993800792604806.\n",
      "[I 2025-09-07 17:50:41,452] Trial 49 finished with value: 3.000429635935488 and parameters: {'lam': 0.0028000764243161533, 'beta': 6.831045540060944}. Best is trial 10 with value: 2.993800792604806.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lam': 0.0010933092269752632, 'beta': 1.0292700573889908}\n",
      "Best value: 2.993800792604806\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    lam = trial.suggest_float(\"lam\", 1e-3, 1.0, log=True)\n",
    "    beta = trial.suggest_float(\"beta\", 1.0, 50.0)\n",
    "\n",
    "    A_est, B_est, info = nocalm(\n",
    "        R_hat,\n",
    "        lam=lam,\n",
    "        beta=beta,\n",
    "        max_steps=2000,\n",
    "        optimizer_type=\"lbfgs\",\n",
    "        lr=0.03,\n",
    "        history_every=500,\n",
    "        dtype=torch.float64,\n",
    "    )\n",
    "\n",
    "    # 最小化最终 loss\n",
    "    return info[\"final_loss\"]\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best value:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b0fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood_true =  2.9921669186153315\n",
      "penalty_true =  0.001691601752228454\n",
      "f_true =  2.99385852036756\n",
      "A_true = \n",
      " [[ 1. -1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0. -1.  1.]]\n",
      "A_est = \n",
      " [[ 1.35652315 -0.24724542  0.34572889]\n",
      " [-0.48937904  0.72751406 -0.4878873 ]\n",
      " [ 0.34712348 -0.24778022  1.35252283]]\n",
      "G_est = \n",
      " [[0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 0.]]\n",
      "likelihood_final =  2.991835124341749\n",
      "penalty_final =  0.002309055115949235\n",
      "f_final =  2.994144179457698\n",
      "Final Loss =  2.9927683578636923\n"
     ]
    }
   ],
   "source": [
    "#print(data.T@ data / 10000)\n",
    "lam = 0.0010933092269752632\n",
    "beta = 1.0292700573889908\n",
    "\n",
    "print(\"likelihood_true = \", likelihood_true)\n",
    "true_penalty = lam * np.sum(np.tanh(beta * np.abs(A_true))[~np.eye(A_true.shape[0], dtype=bool)])\n",
    "f_true = likelihood_true + true_penalty\n",
    "print(\"penalty_true = \", true_penalty)\n",
    "print(\"f_true = \", f_true)\n",
    "\n",
    "A_est, B_est, info = nocalm(\n",
    "    R_hat, lam=lam, beta=beta, \n",
    "    max_steps=2000, optimizer_type=\"lbfgs\", lr=0.1, history_every=1000,\n",
    "    dtype=torch.float64, A_init = np.eye(3))\n",
    "\n",
    "\n",
    "#print(Omega_est)\n",
    "#print(inv(np.eye(3)-W_est.T)@ Omega_est @ inv(np.eye(3)-W_est))\n",
    "#print(\"G_true = \\n\",G_true)\n",
    "print(\"A_true = \\n\",A_true)\n",
    "print(\"A_est = \\n\", A_est)\n",
    "print(\"G_est = \\n\", B_est)\n",
    "likelihood_final = - 2 * np.log(np.linalg.det(A_est)) + np.trace(A_est.T @ R_hat @ A_est)\n",
    "penalty_final = lam * np.sum(np.tanh(beta * np.abs(A_est))[~np.eye(A_est.shape[0], dtype=bool)])\n",
    "print(\"likelihood_final = \",likelihood_final)\n",
    "print(\"penalty_final = \",penalty_final)\n",
    "print(\"f_final = \", likelihood_final + penalty_final)\n",
    "print(\"Final Loss = \", info[\"final_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a5e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
