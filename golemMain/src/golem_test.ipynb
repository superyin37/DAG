{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2e2622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\super\\DAG\\golem-main\\src\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "sys.path.append(r\"C:\\Users\\super\\DAG\")\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "print(os.getcwd())\n",
    "from SCM_data import generate_scm_from_BN \n",
    "from numpy.linalg import inv\n",
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd5fadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\super\\DAG\\golem-main\\src\\models\\golem_model.py:4: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from models import GolemModel\n",
    "from trainers import GolemTrainer\n",
    "from data_loader import SyntheticDataset\n",
    "from data_loader import SCM_data\n",
    "\n",
    "from utils import MEC\n",
    "\n",
    "\n",
    "# For logging of tensorflow messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "def golem(X, lambda_1, lambda_2, equal_variances=True,\n",
    "          num_iter=1e+5, learning_rate=1e-3, seed=1,\n",
    "          checkpoint_iter=None, output_dir=None, B_init=None):\n",
    "    \"\"\"Solve the unconstrained optimization problem of GOLEM, which involves\n",
    "        GolemModel and GolemTrainer.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): [n, d] data matrix.\n",
    "        lambda_1 (float): Coefficient of L1 penalty.\n",
    "        lambda_2 (float): Coefficient of DAG penalty.\n",
    "        equal_variances (bool): Whether to assume equal noise variances\n",
    "            for likelibood objective. Default: True.\n",
    "        num_iter (int): Number of iterations for training.\n",
    "        learning_rate (float): Learning rate of Adam optimizer. Default: 1e-3.\n",
    "        seed (int): Random seed. Default: 1.\n",
    "        checkpoint_iter (int): Number of iterations between each checkpoint.\n",
    "            Set to None to disable. Default: None.\n",
    "        output_dir (str): Output directory to save training outputs.\n",
    "        B_init (numpy.ndarray or None): [d, d] weighted matrix for initialization.\n",
    "            Set to None to disable. Default: None.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: [d, d] estimated weighted matrix.\n",
    "\n",
    "    Hyperparameters:\n",
    "        (1) GOLEM-NV: equal_variances=False, lambda_1=2e-3, lambda_2=5.0.\n",
    "        (2) GOLEM-EV: equal_variances=True, lambda_1=2e-2, lambda_2=5.0.\n",
    "    \"\"\"\n",
    "    # Center the data\n",
    "    X = X - X.mean(axis=0, keepdims=True)\n",
    "\n",
    "    # Set up model\n",
    "    n, d = X.shape\n",
    "    model = GolemModel(n, d, lambda_1, lambda_2, equal_variances, seed, B_init)\n",
    "\n",
    "    # Training\n",
    "    trainer = GolemTrainer(learning_rate)\n",
    "    B_est = trainer.train(model, X, num_iter, checkpoint_iter, output_dir)\n",
    "\n",
    "    return B_est    # Not thresholded yet\n",
    "\n",
    "def weight_to_adjacency(W, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Convert a weight matrix to an adjacency matrix.\n",
    "    \n",
    "    Parameters:\n",
    "        W (np.ndarray): Weight matrix (square matrix).\n",
    "        threshold (float): Values with absolute weight <= threshold are treated as 0.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Binary adjacency matrix of the same shape.\n",
    "    \"\"\"\n",
    "    if not isinstance(W, np.ndarray):\n",
    "        raise TypeError(\"Input W must be a numpy array.\")\n",
    "    if W.shape[0] != W.shape[1]:\n",
    "        raise ValueError(\"Input W must be a square matrix.\")\n",
    "    \n",
    "    G = (np.abs(W) > threshold).astype(int)\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9280c219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:09:53,420 INFO - trainers.golem_trainer - Started training for 10000.0 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 1\n",
      "G_true = \n",
      " [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "G_est = \n",
      " [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:10:04,576 INFO - trainers.golem_trainer - Started training for 10000.0 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 2\n",
      "G_true = \n",
      " [[0 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "G_est = \n",
      " [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:10:16,495 INFO - trainers.golem_trainer - Started training for 10000.0 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 3\n",
      "G_true = \n",
      " [[0 1 0]\n",
      " [0 0 0]\n",
      " [0 1 0]]\n",
      "G_est = \n",
      " [[0 0 0]\n",
      " [1 0 1]\n",
      " [1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:10:27,384 INFO - trainers.golem_trainer - Started training for 10000.0 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 4\n",
      "G_true = \n",
      " [[0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 0]]\n",
      "G_est = \n",
      " [[0 1 0]\n",
      " [0 0 0]\n",
      " [1 1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:10:39,071 INFO - trainers.golem_trainer - Started training for 10000.0 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 5\n",
      "G_true = \n",
      " [[0 1 1]\n",
      " [0 0 1]\n",
      " [0 0 0]]\n",
      "G_est = \n",
      " [[0 1 0]\n",
      " [0 0 0]\n",
      " [1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from data_loader import SyntheticDataset\n",
    "from data_loader.synthetic_dataset import dataset_based_on_B\n",
    "from utils.train import postprocess\n",
    "from utils.utils import count_accuracy, set_seed\n",
    "\n",
    "# Setup for logging\n",
    "# Required for printing histories if checkpointing is activated\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)s - %(name)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Reproducibility\n",
    "set_seed(1)\n",
    "\n",
    "# Load dataset\n",
    "n, d = 1000, 4\n",
    "graph_type, degree = 'ER', 0.5    # ER2 graph\n",
    "B_scale = 1.0\n",
    "noise_type = 'gaussian_ev'\n",
    "#dataset = SyntheticDataset(n, d, graph_type, degree,\n",
    "#                           noise_type, B_scale, seed=1)\n",
    "\n",
    "'''\n",
    "times = 20\n",
    "for i in range(1, 6):\n",
    "    true_count = [0] * 6\n",
    "    for seed in range(times):\n",
    "        X, Y, Z, G_true, CPDAG = SCM_data.generate_scm_data(i,10000, seed = seed)\n",
    "        data = np.array([X, Y, Z]).T\n",
    "        #print(data.T@ data / 10000)\n",
    "        W_est = golem(data, lambda_1=2e-2, lambda_2=5.0,\n",
    "                equal_variances=True, num_iter=1e+4)\n",
    "        G_est = weight_to_adjacency(W_est, 0.05)\n",
    "        if MEC.is_in_markov_equiv_class(G_true, G_est): true_count[i-1] += 1\n",
    "    print(f\"SCM {i} : {true_count[i-1]/times}\")\n",
    "'''\n",
    "\n",
    "for i in range(1, 6):\n",
    "    X, Y, Z, G_true, CPDAG = SCM_data.generate_scm_data(i,10000, seed = 1)\n",
    "    data = np.array([X, Y, Z]).T\n",
    "    W_est = golem(data, lambda_1=2e-2, lambda_2=5.0,\n",
    "                equal_variances=False, num_iter=1e+4)\n",
    "    G_est = weight_to_adjacency(W_est, 0.05)\n",
    "    print(\"pattern\",i)\n",
    "    print(\"G_true = \\n\",G_true)\n",
    "    print(\"G_est = \\n\",G_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c028776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d=4, A->B, B->C, B->D, |v| = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:24:02,258 INFO - trainers.golem_trainer - Started training for 10000.0 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 1\n",
      "G_true = \n",
      " [[0 2 0 0]\n",
      " [0 0 3 4]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "G_est = \n",
      " [[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 1 0]]\n",
      "d=4, A->C, A->D, B->C, B->D, |v| = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:24:13,946 INFO - trainers.golem_trainer - Started training for 10000.0 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 1\n",
      "G_true = \n",
      " [[0 0 2 3]\n",
      " [0 0 3 4]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "G_est = \n",
      " [[0 1 0 0]\n",
      " [0 0 0 0]\n",
      " [0 1 0 0]\n",
      " [1 1 1 0]]\n",
      "d=4, A->D, B->D, C->D, |v| = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:24:25,976 INFO - trainers.golem_trainer - Started training for 100000.0 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 1\n",
      "G_true = \n",
      " [[0 0 0 1]\n",
      " [0 0 0 3]\n",
      " [0 0 0 5]\n",
      " [0 0 0 0]]\n",
      "G_est = \n",
      " [[0 1 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]\n",
      " [0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# A->B, B->C, B->D, |v| = 0\n",
    "print(\"d=4, A->B, B->C, B->D, |v| = 0\")\n",
    "B_true = np.array([\n",
    "    [0, 2, 0, 0],\n",
    "    [0, 0, 3, 4],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0]\n",
    "])\n",
    "N = [1, 4, 3, 2]\n",
    "\n",
    "\n",
    "data, G, B, Sigma = generate_scm_from_BN(B_true.T, n_samples=10000, N=N, seed=42)\n",
    "W_est = golem(data, lambda_1=2e-2, lambda_2=5.0,\n",
    "            equal_variances=False, num_iter=1e+4)\n",
    "G_est = weight_to_adjacency(W_est, 0.05)\n",
    "print(\"pattern\",i)\n",
    "print(\"G_true = \\n\",B_true)\n",
    "print(\"G_est = \\n\",G_est)\n",
    "\n",
    "\n",
    "# A->C, A->D, B->C, B->D, |v| = 2\n",
    "print(\"d=4, A->C, A->D, B->C, B->D, |v| = 2\")\n",
    "B_true = np.array([\n",
    "    [0, 0, 2, 3],\n",
    "    [0, 0, 3, 4],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0]\n",
    "])\n",
    "N = [2, 4, 3, 5]\n",
    "\n",
    "data, G, B, Sigma = generate_scm_from_BN(B_true.T, n_samples=10000, N=N, seed=42)\n",
    "W_est = golem(data, lambda_1=2e-2, lambda_2=5.0,\n",
    "            equal_variances=False, num_iter=1e+4)\n",
    "G_est = weight_to_adjacency(W_est, 0.05)\n",
    "print(\"pattern\",i)\n",
    "print(\"G_true = \\n\",B_true)\n",
    "print(\"G_est = \\n\",G_est)\n",
    "\n",
    "# A->D, B->D, C->D, |v| = 3\n",
    "print(\"d=4, A->D, B->D, C->D, |v| = 3\")\n",
    "\n",
    "B_true = np.array([\n",
    "    [0, 0, 0, 1],\n",
    "    [0, 0, 0, 3],\n",
    "    [0, 0, 0, 5],\n",
    "    [0, 0, 0, 0]\n",
    "])\n",
    "N = [5, 4, 3, 2]\n",
    "\n",
    "data, G, B, Sigma = generate_scm_from_BN(B_true.T, n_samples=10000, N=N, seed=42)\n",
    "W_est = golem(data, lambda_1=0.1, lambda_2=5.0,\n",
    "            equal_variances=False, num_iter=1e+4)\n",
    "G_est = weight_to_adjacency(W_est, 0.05)\n",
    "print(\"pattern\",i)\n",
    "print(\"G_true = \\n\",B_true)\n",
    "print(\"G_est = \\n\",G_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f229731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d=4, A->B, B->C, B->D, |v| = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:29:01,268 INFO - trainers.golem_trainer - Started training for 10000.0 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 1\n",
      "G_true = \n",
      " [[0 2 0 0]\n",
      " [0 0 3 4]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "G_est = \n",
      " [[0 1 0 0]\n",
      " [0 0 1 1]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]]\n",
      "d=4, A->C, A->D, B->C, B->D, |v| = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:29:14,020 INFO - trainers.golem_trainer - Started training for 10000.0 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 1\n",
      "G_true = \n",
      " [[0 0 2 3]\n",
      " [0 0 3 4]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "G_est = \n",
      " [[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [0 0 0 0]]\n",
      "d=4, A->D, B->D, C->D, |v| = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:29:26,517 INFO - trainers.golem_trainer - Started training for 10000.0 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 1\n",
      "G_true = \n",
      " [[0 0 0 1]\n",
      " [0 0 0 3]\n",
      " [0 0 0 5]\n",
      " [0 0 0 0]]\n",
      "G_est = \n",
      " [[0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# A->B, B->C, B->D, |v| = 0\n",
    "print(\"d=4, A->B, B->C, B->D, |v| = 0\")\n",
    "B_true = np.array([\n",
    "    [0, 2, 0, 0],\n",
    "    [0, 0, 3, 4],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0]\n",
    "])\n",
    "N = [1, 4, 3, 2]\n",
    "\n",
    "\n",
    "data, G, B, Sigma = generate_scm_from_BN(B_true.T, n_samples=10000, N=N, seed=42)\n",
    "W_est = golem(data, lambda_1=0.2, lambda_2=5.0,\n",
    "            equal_variances=True, num_iter=1e+4)\n",
    "G_est = weight_to_adjacency(W_est, 0.05)\n",
    "print(\"pattern\",i)\n",
    "print(\"G_true = \\n\",B_true)\n",
    "print(\"G_est = \\n\",G_est)\n",
    "\n",
    "\n",
    "# A->C, A->D, B->C, B->D, |v| = 2\n",
    "print(\"d=4, A->C, A->D, B->C, B->D, |v| = 2\")\n",
    "B_true = np.array([\n",
    "    [0, 0, 2, 3],\n",
    "    [0, 0, 3, 4],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0]\n",
    "])\n",
    "N = [2, 4, 3, 5]\n",
    "\n",
    "data, G, B, Sigma = generate_scm_from_BN(B_true.T, n_samples=10000, N=N, seed=42)\n",
    "W_est = golem(data, lambda_1=0.2, lambda_2=5.0,\n",
    "            equal_variances=True, num_iter=1e+4)\n",
    "G_est = weight_to_adjacency(W_est, 0.05)\n",
    "print(\"pattern\",i)\n",
    "print(\"G_true = \\n\",B_true)\n",
    "print(\"G_est = \\n\",G_est)\n",
    "\n",
    "# A->D, B->D, C->D, |v| = 3\n",
    "print(\"d=4, A->D, B->D, C->D, |v| = 3\")\n",
    "\n",
    "B_true = np.array([\n",
    "    [0, 0, 0, 1],\n",
    "    [0, 0, 0, 3],\n",
    "    [0, 0, 0, 5],\n",
    "    [0, 0, 0, 0]\n",
    "])\n",
    "N = [5, 4, 3, 2]\n",
    "\n",
    "data, G, B, Sigma = generate_scm_from_BN(B_true.T, n_samples=10000, N=N, seed=42)\n",
    "W_est = golem(data, lambda_1=0.2, lambda_2=5.0,\n",
    "            equal_variances=True, num_iter=1e+4)\n",
    "G_est = weight_to_adjacency(W_est, 0.05)\n",
    "print(\"pattern\",i)\n",
    "print(\"G_true = \\n\",B_true)\n",
    "print(\"G_est = \\n\",G_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a40df35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:19:16,280 INFO - trainers.golem_trainer - Started training for 10000.0 iterations.\n",
      "2025-11-25 23:19:28,261 INFO - trainers.golem_trainer - Started training for 10000.0 iterations.\n",
      "2025-11-25 23:19:40,138 INFO - trainers.golem_trainer - Started training for 10000.0 iterations.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([X, Y, Z])\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#print(data.T@ data / 10000)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m W_est \u001b[38;5;241m=\u001b[39m golem(data, lambda_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-2\u001b[39m, lambda_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m,\n\u001b[0;32m      9\u001b[0m         equal_variances\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e+4\u001b[39m)\n\u001b[0;32m     10\u001b[0m G_est \u001b[38;5;241m=\u001b[39m weight_to_adjacency(W_est, \u001b[38;5;241m0.05\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m MEC\u001b[38;5;241m.\u001b[39mis_in_markov_equiv_class(G_true, G_est): true_count[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[1], line 53\u001b[0m, in \u001b[0;36mgolem\u001b[1;34m(X, lambda_1, lambda_2, equal_variances, num_iter, learning_rate, seed, checkpoint_iter, output_dir, B_init)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m     52\u001b[0m trainer \u001b[38;5;241m=\u001b[39m GolemTrainer(learning_rate)\n\u001b[1;32m---> 53\u001b[0m B_est \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain(model, X, num_iter, checkpoint_iter, output_dir)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m B_est\n",
      "File \u001b[1;32mc:\\Users\\super\\DAG\\golem-main\\src\\trainers\\golem_trainer.py:44\u001b[0m, in \u001b[0;36mGolemTrainer.train\u001b[1;34m(self, model, X, num_iter, checkpoint_iter, output_dir)\u001b[0m\n\u001b[0;32m     42\u001b[0m     score, likelihood, h, B_est \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_iter(model, X)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:    \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     score, likelihood, h, B_est \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_iter(model, X)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m%\u001b[39m checkpoint_iter \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_checkpoint(i, score, likelihood, h, B_est, output_dir)\n",
      "File \u001b[1;32mc:\\Users\\super\\DAG\\golem-main\\src\\trainers\\golem_trainer.py:85\u001b[0m, in \u001b[0;36mGolemTrainer.train_iter\u001b[1;34m(self, model, X)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_iter\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, X):\n\u001b[0;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Training for one iteration.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m        numpy.ndarray: [d, d] estimated weighted matrix.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     _, score, likelihood, h, B_est \\\n\u001b[1;32m---> 85\u001b[0m         \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msess\u001b[38;5;241m.\u001b[39mrun([model\u001b[38;5;241m.\u001b[39mtrain_op, model\u001b[38;5;241m.\u001b[39mscore, model\u001b[38;5;241m.\u001b[39mlikelihood, model\u001b[38;5;241m.\u001b[39mh, model\u001b[38;5;241m.\u001b[39mB],\n\u001b[0;32m     86\u001b[0m                          feed_dict\u001b[38;5;241m=\u001b[39m{model\u001b[38;5;241m.\u001b[39mX: X,\n\u001b[0;32m     87\u001b[0m                                     model\u001b[38;5;241m.\u001b[39mlr: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate})\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score, likelihood, h, B_est\n",
      "File \u001b[1;32md:\\coding\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:977\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    974\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 977\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\u001b[38;5;28;01mNone\u001b[39;00m, fetches, feed_dict, options_ptr,\n\u001b[0;32m    978\u001b[0m                      run_metadata_ptr)\n\u001b[0;32m    979\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m    980\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32md:\\coding\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1220\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1220\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_run(handle, final_targets, final_fetches,\n\u001b[0;32m   1221\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1223\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\coding\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1400\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1397\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1400\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m   1401\u001b[0m                        run_metadata)\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1403\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32md:\\coding\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1407\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m   1406\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   1408\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1409\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[1;32md:\\coding\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1390\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[0;32m   1388\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[0;32m   1389\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1390\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1391\u001b[0m                                   target_list, run_metadata)\n",
      "File \u001b[1;32md:\\coding\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1483\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1482\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1483\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf_session\u001b[38;5;241m.\u001b[39mTF_SessionRun_wrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session, options, feed_dict,\n\u001b[0;32m   1484\u001b[0m                                           fetch_list, target_list,\n\u001b[0;32m   1485\u001b[0m                                           run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "times = 20\n",
    "for i in range(1, 6):\n",
    "    true_count = [0] * 6\n",
    "    for seed in range(times):\n",
    "        X, Y, Z, G_true, CPDAG = SCM_data.generate_scm_data(i,10000, seed = seed)\n",
    "        data = np.array([X, Y, Z]).T\n",
    "        #print(data.T@ data / 10000)\n",
    "        W_est = golem(data, lambda_1=2e-2, lambda_2=5.0,\n",
    "                equal_variances=False, num_iter=1e+4)\n",
    "        G_est = weight_to_adjacency(W_est, 0.05)\n",
    "        if MEC.is_in_markov_equiv_class(G_true, G_est): true_count[i-1] += 1\n",
    "    print(f\"SCM {i} : {true_count[i-1]/times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e2faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
